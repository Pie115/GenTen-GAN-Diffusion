{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from TenGAN.ggan.zoo import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = \"/home/spaka002/Tensor_GAN/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(word):\n",
    "    \n",
    "    w = word\n",
    "    \n",
    "    trim_characters = [' ']\n",
    "    trim_characters = {t_c:True for t_c in trim_characters}\n",
    "    \n",
    "    if w[0] in trim_characters:\n",
    "        return trim(w[1:])\n",
    "    \n",
    "    if w[-1] in trim_characters:\n",
    "        return trim(w[:-1])\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id = int(input('config_id'))\n",
    "\n",
    "hps = dict()\n",
    "\n",
    "with open(f'{os.getcwd()}/configs.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    config_txt = text[text.find(f'config_id: {config_id}'):text.find(f'config_id: {config_id+1}')]\n",
    "    del text\n",
    "    \n",
    "use_decomposition = '_NoDecomp' not in config_txt[config_txt.find(\"Generator Model\")+17:config_txt.find(\"Discriminator Model\")-1]\n",
    "\n",
    "hps_text = config_txt.split('{')[-1].split('}')[0]\n",
    "hp_text_list = hps_text.split('\\n')\n",
    "\n",
    "for hp_text in hp_text_list:\n",
    "\n",
    "    if len(hp_text) < 2: continue\n",
    "    hp_name = trim(hp_text.split(':')[0])\n",
    "    hp_value = trim(hp_text.split(':')[1])\n",
    "\n",
    "    if hp_name in ['gen_model', 'disc_model']: hp_value = str(hp_value)\n",
    "    else:\n",
    "        try: hp_value = eval(hp_value)\n",
    "        except: hp_value = str(hp_value)\n",
    "\n",
    "    hps[hp_name] = hp_value\n",
    "    \n",
    "generator_path = config_txt[config_txt.find('saved_generators/'):].split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "substr = 'Tensor Shape'\n",
    "idx = config_txt.find(substr)\n",
    "tensor_shape = eval(trim(config_txt[idx+len(substr)+1: config_txt.find('\\n', idx)]))\n",
    "del substr, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully initialized generator.\n"
     ]
    }
   ],
   "source": [
    "zoo = ModelZoo()\n",
    "gen_class = zoo.get_model(hps['gen_model'])\n",
    "\n",
    "if hps['gen_model'] == 'MyBaselineGenerator': generator = gen_class(generate_tensor_shape = tensor_shape[:-1], opt = hps)\n",
    "elif hps['gen_model'] in ['3DGAN']:\n",
    "    \n",
    "    hps['batch_size'] = 64\n",
    "    hps['lr'] = 1e-2\n",
    "    hps['latent_size'] = 254\n",
    "\n",
    "    hps['num_epochs'] = 10\n",
    "    hps['layer_size'] = 128\n",
    "    hps['latent_dim'] = 100\n",
    "\n",
    "    hps['tensor_shape'] = [25, 51, 51]\n",
    "    hps['hidden_tensor_shape'] = [8, 7, 7, 8]\n",
    "    \n",
    "    generator = gen_class(opt = hps)\n",
    "else:\n",
    "    generator = gen_class(latent_dim = hps['latent_dim'],                     # 1D noise vector input dim\n",
    "                        layer_size = hps['gen_layer_size'],                 # hidden_layer size\n",
    "                        num_nodes = hps['num_nodes'],                       # image height & width\n",
    "                        rank = hps['decomp_rank'],                          # tensor decomposition rank\n",
    "                        num_views = hps['num_views'],                       # num_channels for image\n",
    "                        decomp_type = hps['tensor_model'],                  # decomposition type - 'CPD', 'tucker' only so far\n",
    "                        num_tensor_modes = len(list(tensor_shape))-1,       # number of tensor_modes, exclude mode for batch size\n",
    "                        tensor_decomposition = use_decomposition,\n",
    "                        opt = hps\n",
    "                        )\n",
    "\n",
    "generator_state_dict = torch.load(generator_path)\n",
    "generator.load_state_dict(generator_state_dict)\n",
    "\n",
    "del zoo, gen_class, generator_path, generator_state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Real & Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.change_device('cpu')\n",
    "generated_images = generator.generate(n_samples).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_comparison = torch.load(f\"{work_dir}TenGAN/my_data/sample_EleEscan_1_1-5.pt\")\n",
    "# tensor_comparison = torch.load(f\"{work_dir}TenGAN/my_data/torch_GammaEscan_RandomAngle_1_1&2&5.pt\")\n",
    "# tensor_comparison = torch.from_numpy(tensor_comparison)\n",
    "\n",
    "tensor_comparison = tensor_comparison.permute(0, 3, 1, 2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_indices = set()\n",
    "\n",
    "# while len(sample_indices) < n_samples:\n",
    "#     new_index = int(random.random()*real_data.shape[0])\n",
    "#     sample_indices.add(new_index)\n",
    "# sample_indices = list(sample_indices)\n",
    "\n",
    "# tensor_comparison = real_data[sample_indices].permute(0, 3, 1, 2).numpy()\n",
    "# del real_data, new_index, sample_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_comparison_torch min/max: 0 255\n",
      "generated_images_torch min/max: 0 255\n",
      "tensor_comparison_torch shape: torch.Size([500, 25, 51, 51])\n",
      "generated_images_torch shape: torch.Size([500, 25, 51, 51])\n"
     ]
    }
   ],
   "source": [
    "#First we have to normalize the data, the frechet inception distance from pytorch only takes uint8 data, \n",
    "# so we first normalize so our data is between 0 and 1\n",
    "\n",
    "tensor_comparison_norm = (tensor_comparison[:n_samples] - tensor_comparison[:n_samples].min()) / (tensor_comparison[:n_samples].max() - tensor_comparison[:n_samples].min())\n",
    "generated_images_norm = (generated_images - generated_images.min()) / (generated_images.max() - generated_images.min())\n",
    "\n",
    "# Now multiply by 255 to [0, 255] and convert to uint8\n",
    "tensor_comparison_uint8 = (tensor_comparison_norm * 255).astype(np.uint8)\n",
    "generated_images_uint8 = (generated_images_norm * 255).astype(np.uint8)\n",
    "\n",
    "tensor_comparison_torch = torch.tensor(tensor_comparison_uint8, dtype=torch.uint8)\n",
    "generated_images_torch = torch.tensor(generated_images_uint8, dtype=torch.uint8)\n",
    "\n",
    "print(\"tensor_comparison_torch min/max:\", tensor_comparison_torch.min().item(), tensor_comparison_torch.max().item())\n",
    "print(\"generated_images_torch min/max:\", generated_images_torch.min().item(), generated_images_torch.max().item())\n",
    "print(\"tensor_comparison_torch shape:\", tensor_comparison_torch.shape)\n",
    "print(\"generated_images_torch shape:\", generated_images_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this and the last score are the same, I'm assuming these are the correct way to do it.\n",
    "\n",
    "real_dataset = tensor_comparison_torch.unsqueeze(1).repeat(1, 3, 1, 1, 1).view(-1, 3, 51, 51)\n",
    "generated_dataset = generated_images_torch.unsqueeze(1).repeat(1, 3, 1, 1, 1).view(-1, 3, 51, 51)\n",
    "random_dataset = torch.tensor(torch.randint(low = 0, high = 255+1, size = (real_dataset.shape[0], 3, 51, 51)), dtype = torch.uint8)\n",
    "\n",
    "del tensor_comparison_norm, generated_images_norm, tensor_comparison_uint8, generated_images_uint8\n",
    "del tensor_comparison_torch, generated_images_torch, tensor_comparison, generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(real_dataset, fake_dataset, device = 'cpu'):\n",
    "\n",
    "    fid = FrechetInceptionDistance(feature = 2048).to(device)\n",
    "    fid.update(real_dataset.to(device), real=True)\n",
    "    fid.update(fake_dataset.to(device), real=False)\n",
    "    \n",
    "    fid_score_dataset = fid.compute().item()\n",
    "\n",
    "    return float(fid_score_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display FID Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ID: 39\n",
      "Generated Data FID: 240.0154266357422\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "print(f\"Config ID: {config_id}\")\n",
    "print(f\"Generated Data FID: {get_fid(real_dataset, generated_dataset, device = device)}\")\n",
    "if False: print(f\"Random Data FID: {get_fid(real_dataset, random_dataset, device = device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Hyperparameters:\n",
      "\n",
      "do_cnn_slices = False\n",
      "n_epochs = 1\n",
      "batch_size = 64\n",
      "gen_lr = 1e-05\n",
      "disc_lr = 0.001\n",
      "latent_dim = 100\n",
      "num_nodes = 51\n",
      "num_views = 25\n",
      "num_time_steps = 9\n",
      "val_gen_size = 100\n",
      "tensor_model = CPD\n",
      "decomp_rank = None\n",
      "training_size = 10000\n",
      "epoch_print_every = 1\n",
      "batch_print_every = 5\n",
      "critic_iterations = 1\n",
      "generator_iterations = 1\n",
      "gen_model = 3DGAN\n",
      "gen_layer_size = 128\n",
      "gen_hidden_channels = 64\n",
      "gen_num_hidden_convs = 1\n",
      "gen_inconsistency_lambda = 0\n",
      "gen_epoch_start_inc = 1000\n",
      "gen_add_noise = ['mulitply', [0.5, 2]]\n",
      "gen_channel_smooth = 0\n",
      "gen_channel_smooth_window = 3\n",
      "gen_smooth_modes = []\n",
      "gen_epoch_start_smooth = 0\n",
      "disc_model = Discriminator3d\n",
      "num_slices = 25\n",
      "disc_sig_out = False\n",
      "disc_add_noise = None\n",
      "disc_conv_out_channels = 16\n",
      "disc_conv_hidden_channels = 32\n",
      "disc_num_conv_layers = 2\n",
      "disc_linear_hidden_dim = 64\n",
      "disc_num_linear_layers = 1\n",
      "max_eval_rank = 40\n",
      "tensor_eval_samples = 50\n",
      "rank_lambda = 0\n",
      "penalty_type = fro\n",
      "rank_penalty_method = A\n",
      "n_graph_sample_batches = 10\n",
      "eval_method = multiview\n",
      "eval_every = 0\n",
      "device = cpu\n",
      "num_tensor_modes = 3\n",
      "lr = 0.01\n",
      "latent_size = 254\n",
      "num_epochs = 10\n",
      "layer_size = 128\n",
      "tensor_shape = [25, 51, 51]\n",
      "hidden_tensor_shape = [8, 7, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(f\"{' '*5}Hyperparameters:\\n\\n\" + '\\n'.join([f\"{hp} = {hps[hp]}\" for hp in list(hps)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
